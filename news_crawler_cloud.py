import streamlit as st
import pandas as pd
import datetime as dt
from datetime import datetime
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from urllib.parse import quote
import urllib.request as req
import bs4
from pandas.tseries.offsets import BusinessDay
import warnings
import json

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# --- 1. ä»‹é¢åˆå§‹åŒ– ---
st.set_page_config(page_title="ç¶ èƒ½æ–°èç™¼ä½ˆç³»çµ±", page_icon="âš¡", layout="wide")

# åˆå§‹åŒ– session_stateï¼Œç¢ºä¿ç·¨è¼¯çµæœä¸æœƒæ¶ˆå¤±
if 'edited_df' not in st.session_state:
    st.session_state.edited_df = pd.DataFrame()

# --- 2. å·¥å…·å‡½å¼ ---
def extract_webpage_text(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, "html.parser")
        for tag in ['article', 'main', 'div']:
            content = soup.find(tag)
            if content and len(content.text.strip()) > 200:
                return content.get_text(separator="\n", strip=True)
        return soup.get_text(separator="\n", strip=True)
    except:
        return ""

def send_python_email(df):
    try:
        sender = st.secrets["EMAIL_SENDER"]
        password = st.secrets["EMAIL_PASSWORD"]
        receiver = st.secrets["EMAIL_RECEIVER"]
        
        msg = MIMEMultipart()
        msg['Subject'] = f"ã€{datetime.now().strftime('%m/%d')}ã€‘ç¶ èƒ½ç”¢æ¥­æ–°èæ•´ç†"
        msg['From'] = f"æ–°èæ©Ÿå™¨äºº <{sender}>"
        msg['To'] = receiver

        html_rows = ""
        for _, row in df.iterrows():
            # ç™¼ä¿¡æ™‚ä½¿ç”¨çœŸæ­£çš„ç¶²å€é€£çµ
            target_url = row['ç¶²å€']
            html_rows += f"""
            <tr>
                <td style='border:1px solid #ddd; padding:8px;'>{row['æ—¥æœŸ']}</td>
                <td style='border:1px solid #ddd; padding:8px;'><a href='{target_url}'>{row['æ¨™é¡Œ']}</a></td>
                <td style='border:1px solid #ddd; padding:8px;'>{row.get('AI æ–°èæ‘˜è¦', '')}</td>
            </tr>"""
        
        html_body = f"<html><body><h3>ä»Šæ—¥æ–°èæ•´ç†</h3><table border='1' style='border-collapse:collapse; width:100%;'><thead><tr style='background-color:#f2f2f2;'><th>æ—¥æœŸ</th><th>æ¨™é¡Œ</th><th>æ‘˜è¦</th></tr></thead><tbody>{html_rows}</tbody></table></body></html>"
        msg.attach(MIMEText(html_body, 'html'))
        
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(sender, password)
            server.send_message(msg)
        return True
    except Exception as e:
        st.error(f"éƒµä»¶ç™¼é€å¤±æ•—: {e}")
        return False

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("âš¡ ç¶ èƒ½ç™¼ä½ˆç³»çµ±")
    
    st.header("1ï¸âƒ£ æŠ“å–æ–°èè³‡æ–™")
    today_dt = pd.Timestamp.now().normalize()
    last_bus_day = (today_dt - BusinessDay(1)).to_pydatetime()
    s_date = st.date_input("é–‹å§‹æ—¥æœŸ", last_bus_day)
    e_date = st.date_input("çµæŸæ—¥æœŸ", today_dt)
    
    if st.button("ğŸš€ åŸ·è¡Œçˆ¬èŸ²", use_container_width=True):
        with st.spinner("æ­£åœ¨åŸ·è¡Œçˆ¬èŸ²ç¨‹å¼..."):
            start_date_obj = datetime.combine(s_date, datetime.min.time())
            end_date_obj = datetime.combine(e_date, datetime.max.time())
            
            dates, sources, categories, titles, links = [], [], [], [], []
            keywords = ["å¤ªé™½èƒ½", "å†ç”Ÿèƒ½æº", "é›»å» ", "ç¶ é›»", "å…‰é›»",  "é¢¨é›»", "å„²èƒ½", "ç¶ é›»äº¤æ˜“", "éº—å‡èƒ½æº", "ç¶ èƒ½"]
            title_keywords = ["å°æ°´åŠ›","å…‰é›»","ç¶ èƒ½","ç¶ é›»","é¢¨èƒ½","å¤ªé™½èƒ½","å†ç”Ÿ","å„²èƒ½","æ¸›ç¢³","ESG","é›»æ± ","åœ°ç†±","é¢¨åŠ›","ç™¼é›»","é­šå¡­","åœŸåœ°","æ°´åŠ›","æ·¨é›¶","æ¼é›»","å…‰å„²","ä½åœ°åŠ›","å”®é›»","å°é›»","é…é›»","è¼¸é›»","å‡å£“","ç’°ç¤¾","ç”¨é›»å¤§æˆ¶","é¥‹ç·š","é›»è¡¨","è¡¨å‰","è¡¨å¾Œ","éœ€é‡åæ‡‰","é›»ç¶²","åœŸåœ°é–‹ç™¼","é›»å» ","å‚™è½‰","èª¿é »","PCS","EMS","BMS","é›»åŠ›äº¤æ˜“","ä½µç¶²","ç±Œè¨­","é¢¨é›»","é›»åƒ¹","é›»æ¥­","é¦™å¤¾è˜­","è¾²æ¥­è£œåŠ©","CPPA","è¾²é›»","è¾²æ¥­è¨­æ–½è¨±å¯","æ²¼æ°£","ç”Ÿè³ªèƒ½","Solar","PV","energy","solar","storage","å…‰ä¼","èƒ½æºæ”¿ç­–","ç¢³æ¬Š","ç¢³è²»","èº‰è³¼","èƒ½æºç½²","é›»æ¥­æ³•","èº‰è³¼è²»ç‡","æ¼é›»å…±ç”Ÿ"]

            def append_news(title, url, date_obj, source, category):
                if start_date_obj <= date_obj <= end_date_obj:
                    if any(k in title for k in title_keywords):
                        dates.append(date_obj.strftime("%Y-%m-%d"))
                        sources.append(source)
                        categories.append(category)
                        titles.append(title)
                        links.append(url)

            headers = {"User-Agent": "Mozilla/5.0"}
            for kw in keywords:
                try: # Yahoo çˆ¬èŸ²
                    res = requests.get(f"https://tw.news.yahoo.com/search?p={quote(kw)}", headers=headers)
                    soup = BeautifulSoup(res.text, "html.parser")
                    for art in soup.select("li div[class*='Cf']"):
                        a = art.find("a")
                        m = art.find("div", class_="C(#959595)")
                        if a and m:
                            t, l = a.text.strip(), a["href"]
                            full_l = l if l.startswith("http") else f"https://tw.news.yahoo.com{l}"
                            t_str = m.text.strip().split("â€¢")[-1].strip()
                            d_obj = datetime.now()
                            if "å¤©å‰" in t_str: d_obj -= dt.timedelta(days=int(t_str.replace("å¤©å‰","")))
                            elif "å°æ™‚" in t_str or "åˆ†é˜" in t_str: pass
                            else:
                                try: d_obj = datetime.strptime(t_str.replace("æ—©ä¸Š","").replace("ä¸‹åˆ","").replace("å¹´","-").replace("æœˆ","-").replace("æ—¥","").split()[0], "%Y-%m-%d")
                                except: continue
                            append_news(t, full_l, d_obj, "Yahoo", kw)
                except: continue
                try: # UDN çˆ¬èŸ²
                    res = requests.get(f"https://udn.com/search/word/2/{quote(kw)}", headers=headers)
                    soup = BeautifulSoup(res.text, "html.parser")
                    ti_box = soup.find("div", class_="context-box__content story-list__holder story-list__holder--full")
                    if ti_box:
                        ti_h2 = ti_box.find_all("h2")
                        ti_time = ti_box.find_all("time", class_="story-list__time")
                        for idx, h2 in enumerate(ti_h2):
                            a = h2.find("a")
                            if a and idx < len(ti_time):
                                try:
                                    d_obj = datetime.strptime(ti_time[idx].text.strip()[:10], "%Y-%m-%d")
                                    append_news(a.text.strip(), a["href"], d_obj, "UDN", kw)
                                except: continue
                except: continue

            if titles:
                df = pd.DataFrame({
                    "æ—¥æœŸ": dates, "ä¾†æº": sources, "åˆ†é¡": categories,
                    "æ¨™é¡Œ": titles, "ç¶²å€": links, "AI æ–°èæ‘˜è¦": ""
                }).drop_duplicates(subset=["æ¨™é¡Œ"]).sort_values(by="æ—¥æœŸ", ascending=False)
                
                # --- å¼·åˆ¶å°‡é¡¯ç¤ºæ¬„ä½æ”¹æˆ "(æŸ¥çœ‹)" ---
                df["åŸæ–‡é€£çµ"] = df["ç¶²å€"] # è¤‡è£½ä¸€ä»½åŸå§‹ç¶²å€ä¾› LinkColumn ä½¿ç”¨
                st.session_state.edited_df = df
                st.success(f"âœ… æŠ“å–å®Œæˆï¼å…± {len(df)} ç­†æ–°èã€‚")
            else:
                st.error("âŒ æ­¤æ—¥æœŸç¯„åœå…§æŸ¥ç„¡æ–°èã€‚")

    st.divider()

    # æ­¥é©ŸäºŒï¼šç”¢ç”Ÿæ‘˜è¦
    st.header("2ï¸âƒ£ ç”¢ç”Ÿæ‘˜è¦")
    if st.button("ğŸ¤– ç”¢ç”Ÿæ‘˜è¦", use_container_width=True):
        if not st.session_state.edited_df.empty:
            client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
            for idx, row in st.session_state.edited_df.iterrows():
                if not row['AI æ–°èæ‘˜è¦']:
                    st.write(f"æ­£åœ¨æ‘˜è¦: {row['æ¨™é¡Œ'][:15]}...")
                    text = extract_webpage_text(row['ç¶²å€'])
                    if text:
                        res = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": f"è«‹ä»¥ç¹é«”ä¸­æ–‡æ‘˜è¦ç´„40å€‹å­—ï¼š\n\n{text[:2500]}"}]
                        )
                        st.session_state.edited_df.at[idx, 'AI æ–°èæ‘˜è¦'] = res.choices[0].message.content.strip()
            st.rerun()

    st.divider()

    # æ­¥é©Ÿä¸‰ï¼šæ­£å¼ç™¼ä¿¡
    st.header("3ï¸âƒ£ æ­£å¼ç™¼ä¿¡")
    if st.button("ğŸ“§ ç™¼é€é›»å­å ±", use_container_width=True):
        if not st.session_state.edited_df.empty:
            if send_python_email(st.session_state.edited_df):
                st.balloons()
                st.success("âœ… éƒµä»¶ç™¼é€æˆåŠŸï¼")
        else:
            st.warning("âš ï¸ ç•«é¢ä¸Šæ²’æœ‰è³‡æ–™ã€‚")

# --- 4. ä¸»ç•«é¢ ---
st.write("### ğŸ“ ç·¨è¼¯ç™¼ä½ˆæ¸…å–®")
st.caption("æç¤ºï¼šé»æ“Šã€Œ(æŸ¥çœ‹)ã€å¯è·³è½‰åŸæ–‡ï¼›é¸å–è¡Œä¸¦æŒ‰ Delete å¯åˆªé™¤ã€‚")

if not st.session_state.edited_df.empty:
    # é€™è£¡æˆ‘å€‘æ¡å–æœ€ä¿éšªçš„åšæ³•ï¼š
    # ä½¿ç”¨ä¸€æ¬„éš±è—çš„åŸå§‹ç¶²å€ä¾†é©…å‹• LinkColumn çš„é»æ“Šè¡Œç‚ºï¼Œ
    # ä¸¦ä¸”å¼·åˆ¶è®“é¡¯ç¤ºæ–‡å­—ç‚º "(æŸ¥çœ‹)"ã€‚
    st.session_state.edited_df = st.data_editor(
        st.session_state.edited_df,
        num_rows="dynamic",
        use_container_width=True,
        column_config={
            "æ—¥æœŸ": st.column_config.TextColumn("æ—¥æœŸ", disabled=True),
            "ä¾†æº": st.column_config.TextColumn("ä¾†æº", disabled=True),
            "æ¨™é¡Œ": st.column_config.TextColumn("æ¨™é¡Œ", width="large"),
            "åŸæ–‡é€£çµ": st.column_config.LinkColumn(
                "åŸæ–‡é€£çµ",
                display_text="(æŸ¥çœ‹)", # å†æ¬¡æ˜ç¢ºæŒ‡å®š
                width="small"
            ),
            "ç¶²å€": None, # å¾¹åº•éš±è—åŸå§‹ç¶²å€æ¬„ä½ï¼Œä¸è®“å®ƒå‡ºç¾åœ¨ç•«é¢ä¸Š
            "AI æ–°èæ‘˜è¦": st.column_config.TextColumn("AI æ–°èæ‘˜è¦", width="large")
        },
        column_order=["æ—¥æœŸ", "ä¾†æº", "æ¨™é¡Œ", "åŸæ–‡é€£çµ", "AI æ–°èæ‘˜è¦"]
    )
else:
    st.info("ğŸ‘ˆ è«‹å…ˆå¾å·¦å´åŸ·è¡Œã€Œæ­¥é©Ÿä¸€ã€æŠ“å–æ–°èã€‚")
